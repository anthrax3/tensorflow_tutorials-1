{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets\n",
    "\n",
    "Bu notebook'ta öncelikle hard disk'teki imageları parçalar halinde okuyup, sonrasında bir CNN öğreneceğiz. CNNlerle ilgili en anlaşılır bilgiyi [şu](http://www.deeplearningbook.org/contents/convnets.html) linkte bulabilirsiniz (İngilizce kaynak).\n",
    "\n",
    "Bu CNN'in amacı, köpek fotoğraflarından köpeklerin hangi türe ait olduğunu öğrenmek. Bu verisetini kullanabilmek için Kaggle'daki [yarışmadan](https://www.kaggle.com/c/dog-breed-identification) indirmek gerekiyor. Ben train verisetini indirip \"dog_data/train\" diye bir klasörün içine attım. Sınıfların etiketleri ise \"dog_data/labels.csv\" içinde. Siz farklı bir klasör kullanırsanız aşağıdaki directory değişkenlerini ona göre belirlemeniz gerek.\n",
    "\n",
    "Şimdi kütüphaneleri ve fonksiyonları oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elvan/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "\n",
    "def load_images(input_dir, batch_shape):\n",
    "    \"\"\"Girdi klasöründen görselleri parça parça oku,\n",
    "        Image'ı istenilen boyuta resize edip kare hale getirmek için siyah padding ekle.\n",
    "      Args:\n",
    "        input_dir: Görsellerin bulunduğu girdi klasörünün adresi\n",
    "        batch_shape: parça şekli, i.e. [batch_size, height, width, 3]\n",
    "      Yields:\n",
    "        filenames: Dosyaların adres ve uzantı olmadan isimleri\n",
    "        images: bu batch'teki görselleri içeren bir array\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in tf.gfile.Glob(os.path.join(input_dir, '*.jpg')):\n",
    "        image = Image.open(filepath)\n",
    "        img_w, img_h = image.size\n",
    "        ims = [img_w, img_h]\n",
    "        max_p = np.argmax(ims)\n",
    "        max_v = ims[max_p]\n",
    "        min_v = ims[1-max_p]\n",
    "        new_size = (batch_shape[1], batch_shape[2])\n",
    "        bg = Image.new(\"RGB\", new_size)\n",
    "        rat = float(batch_shape[1])/max_v\n",
    "        new_max = rat*max_v\n",
    "        new_min = rat*min_v\n",
    "        ims[max_p] = int(new_max)\n",
    "        ims[1-max_p] = int(new_min)\n",
    "        image = image.resize(ims)\n",
    "        bg.paste(image, (int((new_size[0]-ims[0])/2),\n",
    "                      int((new_size[1]-ims[1])/2)))\n",
    "        image = np.array(bg).astype(np.float) / 255 # 0-255 arasındaki image'ı 0-1 arasına getir\n",
    "        images.append(image)\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            images = np.array(images)\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = []\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        images = np.array(images)\n",
    "        yield filenames, images\n",
    "\n",
    "def get_labels(all_labels, filenames):\n",
    "    classes = []\n",
    "    for fname in filenames:\n",
    "        fname = fname.replace(\".jpg\",\"\")\n",
    "        classes.append(all_labels[fname])\n",
    "    return(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öncelikle yapmak istediğimiz şey, görsellerimizi yükleyip, istediğimiz formata getirip bize verecek bir fonksiyon yazmak. Veri setimizdeki görseller maalesef aynı boyutta değil, hatta boyutları birbirinden gerçekten çok farklı. Bu yüzden bu görselleri CNN'e verebilmek için standartlaştırmamız gerekiyor. Standartlaştırmamız gerekmeyen CNN yapıları da mevcut ancak şimdilik oraya girmiyoruz. Ben gayet rastgele olarak görsellerin 128 x 128 olması gerektiğine karar verdim. Bu değeri siz aşağıdaki 'im_size' değerini değiştirerek belirleyebilirsiniz. \n",
    "\n",
    "Dikkat edilmesi gereken bir diğer nokta görsellerin kare olmadığı gerçeği. Bu yüzden, görseldeki objelerin proporsiyonunu bozmamak adına kısa olan kenara siyah şeritler eklemeye karar verdim. Bu önişleme yöntemi tamamen kişinin seçimine kalmış bir şey. Siz başka şeyler de deneyebilirsiniz.\n",
    "\n",
    "'load_images' fonksiyonu, veri setimizi yüklemek için oluşturduğumuz bir generator fonksiyonu. Bu fonksiyon sırasıyla şunları yapıyor:\n",
    "\n",
    "- Dosyaların olduğu klasörün adresini alıyor\n",
    "- Bu adresteki '.jpg' uzantılı dosyaları buluyor.\n",
    "- Bu dosyaları, sırasıyla, batch_size'a kadar olacak şekilde açıyor\n",
    "- Açtığı image'ı belli bir boyuta getirmek için şunları yapıyor:\n",
    "    - Image'ın hangi boyutunun büyük olduğunu buluyor\n",
    "    - im_size'ın büyük olan kenara oranını buluyor\n",
    "    - Bu orana göre büyük olan kenarı im_size'a, küçük olan kenarı ise yine bu orana bağlı olarak daha küçük bir değere çekiyor\n",
    "    - Küçük olan kenarı im_size'a tamamlamak için siyah bir şerit çekiyor.\n",
    "- Image istenilen boyuta geldikten sonra image'ı normalize edip array'e ekliyor\n",
    "- Array boyutu batch_size'a ulaşınca bu array'i ve array'deki dosyaların isimlerini döndürüyor\n",
    "- Bunu klasördeki tüm imagelar dönene kadar yapıyor\n",
    "\n",
    "Dikkat ederseniz bu fonksiyon klasördeki image sayısından bağımsız olarak çalışıyor. Bu python generatorlarının bir getirisi. 'yield' anahtar kelimesini araştırarak generatorlar nasıl çalışıyor öğrenebilirsiniz.\n",
    "\n",
    "İkinci oluşturduğumuz fonksiyon ise dosya ismiyle bize sınıfı döndürüyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki hücre'de önce görsellerin etiketlerini alıyoruz. Bu etiketler kategorik olarak verilmiş durumda. Ancak tensorflow'da kategorik değişkenlerle çalışamıyoruz. Bu kategorik sınıfları, numerik sınıflara çevirmek gerekiyor. Bunu da Scikit-learn kütüphanesinden 'LabelEncoder' fonksiyonu ile yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "      <th>num_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed  num_labels\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull          19\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo          37\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese          85\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick          15\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever          49"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = os.getcwd() + \"/dog_data/train/\"\n",
    "label_dir = os.getcwd() + \"/dog_data/labels.csv\"\n",
    "labels = pd.read_csv(label_dir)\n",
    "batch_size = 100 # Kafamıza göre belirledik, normalde 16, 32, 50 gibi değerler olur\n",
    "im_size = 28 # Kafamıza göre belirledik\n",
    "batch_shape = [batch_size, im_size, im_size, 3]\n",
    "\n",
    "# Kategorik değişkeni numerik yap\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels[\"breed\"])\n",
    "num_class = len(le.classes_)\n",
    "print(num_class)\n",
    "labels[\"num_labels\"] = le.transform(labels[\"breed\"])\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrame'i dictionary'ye çevir\n",
    "all_labels = labels.set_index('id')['num_labels'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi hep yaptığımız gibi tensorflow değişkenlerini ve graph'ı tanımlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ağırlıkları ve bias'ı başlatacak fonksiyonlar\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Layerları oluşturan fonksiyonlar\n",
    "def conv2d(x, W): # Convolution layer\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x): # Max pool layer\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "conv_size = 15\n",
    "\n",
    "# 5x5 convolution 32 feature\n",
    "W_conv1 = weight_variable([conv_size, conv_size, 3, 32])\n",
    "\n",
    "# 32 bias\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = (None, im_size, im_size, 3), name = \"x\")\n",
    "y_ = tf.placeholder(tf.int64, shape = (None), name = \"y_\")\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([conv_size, conv_size, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([int(im_size/4) * int(im_size/4) * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, int(im_size/4)*int(im_size/4)*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, num_class])\n",
    "b_fc2 = bias_variable([num_class])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "correct = tf.nn.in_top_k(y_conv, y_, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training batch average accuracy 0.00864078\n",
      "step 1, training batch average accuracy 0.0136452\n",
      "step 5, training batch average accuracy 0.0148102\n",
      "step 6, training batch average accuracy 0.0166549\n",
      "step 7, training batch average accuracy 0.020256\n",
      "step 8, training batch average accuracy 0.0244837\n",
      "step 9, training batch average accuracy 0.0297264\n",
      "step 10, training batch average accuracy 0.032639\n",
      "step 11, training batch average accuracy 0.0380847\n",
      "step 12, training batch average accuracy 0.0434775\n",
      "step 13, training batch average accuracy 0.0489232\n",
      "step 14, training batch average accuracy 0.0568932\n",
      "step 15, training batch average accuracy 0.0641748\n",
      "step 16, training batch average accuracy 0.0717476\n",
      "step 17, training batch average accuracy 0.0808297\n",
      "step 18, training batch average accuracy 0.0937423\n",
      "step 19, training batch average accuracy 0.104907\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    prev_accuracy = 0\n",
    "    for i in range(20):\n",
    "        bname = 0\n",
    "        tr_accur = 0\n",
    "        for filenames, images in load_images(image_dir, batch_shape):\n",
    "            bname += 1\n",
    "            y_temp = get_labels(all_labels, filenames)\n",
    "            train_step.run(feed_dict={x: images, y_: y_temp, keep_prob: 0.8})\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: images, y_: y_temp, keep_prob: 1.0})\n",
    "            tr_accur += train_accuracy\n",
    "        tr_accur /= bname\n",
    "        if(tr_accur > prev_accuracy):\n",
    "            print('step %d, training batch average accuracy %g' % (i, tr_accur))\n",
    "            prev_accuracy = tr_accur\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49000001"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
