{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron\n",
    "\n",
    "Bu notebook'te MNIST verisetini kullanarak basit bir çok katmanlı perceptron yapay sinir ağı eğiteceğiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elvan/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Değişkenleri ve placeholderları oluşturalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 28*28 # MNIST 28x28 görsellerden oluşuyor. Bunları 1D Tensöre çeviriyoruz.\n",
    "n_hid1 = 250\n",
    "n_hid2 = 150\n",
    "n_outputs = 10\n",
    "learning_rate = 0.0001\n",
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d&H%M%S\")\n",
    "root_logdir = \"tf_logs_mlp\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"X\")\n",
    "y = tf.placeholder(tf.int64, shape = (None), name = \"y\")\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Değişkenleri tanımladıktan sonra Graph'ımızı oluşturabiliriz. Bu noktada \"name scope\" konseptinden bahsetmek gerekiyor. \"Name scope\"ları kullanarak aynı yapıya sahip işlemleri bir araya gruplayabiliriz. Bu işlem her ne kadar opsiyonel olsa da, hem graph'ınızın daha temiz olmasını sağlayacak hem de kodu kendi içerisinde bölümlere ayırarak okunabilirliğini arttıracaktır.\n",
    "\n",
    "Network scope'unda 250X150X10 yapısına sahip bir Multilayer Perceptron modeli oluşturduk. Gizli katmanlarımızın aktivasyon fonksiyonları, fully_connected fonksiyonunun default aktivasyon fonksiyonu olan RELU. RELU fonksiyonu isim olarak çok büyük olsa da aslında çok basit bir fonksiyon. \n",
    "\n",
    "$$RELU(x) = max(0, x)$$\n",
    "\n",
    "Kısacası RELU fonksiyonu girdisi 0'dan büyükse girdisini, değilse 0 döndürüyor. Eğer aktivasyon fonksiyonunu değiştirmek istiyorsanız 'activation_fn' parametresiyle bunu belirleyebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Scope'u\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hid1 = fully_connected(X, n_hid1, scope = \"hid1\")\n",
    "    hid2 = fully_connected(hid1, n_hid2, scope = \"hid2\") # Hidden 1'in output'u, Hidden 2'nin input'u oluyor\n",
    "    logits = fully_connected(hid2, n_outputs, scope = \"outputs\", activation_fn = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss scope'unda, modelin nasıl öğrenileceğini belirttik. Modeli \"Cross Entropy\" fonksiyonunu optimize ederek öğreneceğimizi belirttik.\n",
    "\n",
    "Multi-class sınıflandırmayı normalde burada olduğu gibi 'Soft-max' fonksiyonuyla yapıyoruz. Ancak dikkat ettiyseniz bu fonksiyonu network scope'unda aktivasyon fonksiyonu olarak tanımlamadık. Bunun sebebi kullandığımız \"sparse_softmax_cross_entropy_with_logits\" kayıp fonksiyonunun içinde zaten softmax işlemi bulunması. Bu fonksiyonun güzel tarafı, logitlerin 0 olduğu durumda bile çalışacak şekilde sparse olarak yazılmış olması. Bu sayede potansiyel hataların önüne geçmiş oluyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss Scope'u\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öğrenme scope'unda TF'a kullanacağımız optimizasyon yöntemini ve minimize edeceğimiz değeri veriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Scope'u\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Değerlendirme scope'unda ise modelin başarısını nasıl değerlendireceğimizi TF'a bildiriyoruz. Bu kısımda doğru tahmin yüzdesi olan 'accuracy' metriğini kullanmayı seçtim. Bunu yapabilmek için 'in_top_k' fonksiyonunu kullanabiliriz. Bu fonksiyon size, doğru sınıfın yaptığınız sınıf tahminin ilk 'k' değer içinde olup olmadığını verir. k'yı 1 seçtiğimizde ise ilk tahminimizin doğru tahmin olup olmadığını öğreniriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son olarak değişkenlerimizi ve işlemlerimizi başlatarak, loglarımızı oluşturuyoruz. Bu noktada, önceki notebook'tan farklı olarak, modelimizi daha sonra kullanmak üzere kaydedeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "acc_summary = tf.summary.scalar('Train_Accuracy', accuracy)\n",
    "acc_summary_test = tf.summary.scalar('Test_Accuracy', accuracy)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kodu artık koşturabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.08 Test Accuracy: 0.1065\n",
      "Epoch: 10 Train Accuracy: 0.8 Test Accuracy: 0.7154\n",
      "Epoch: 20 Train Accuracy: 0.76 Test Accuracy: 0.8086\n",
      "Epoch: 30 Train Accuracy: 0.82 Test Accuracy: 0.8455\n",
      "Epoch: 40 Train Accuracy: 0.88 Test Accuracy: 0.8642\n",
      "Epoch: 50 Train Accuracy: 0.82 Test Accuracy: 0.8768\n",
      "Epoch: 60 Train Accuracy: 0.84 Test Accuracy: 0.8853\n",
      "Epoch: 70 Train Accuracy: 0.88 Test Accuracy: 0.8898\n",
      "Epoch: 80 Train Accuracy: 0.82 Test Accuracy: 0.8947\n",
      "Epoch: 90 Train Accuracy: 0.94 Test Accuracy: 0.8985\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run() # Değişkenleri başlat\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size): # batch sayısını modulo aritmetiği ile hesapla\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict = {X: X_batch, y:y_batch})\n",
    "            if(iteration % 10 == 0):\n",
    "                summary_str = acc_summary.eval(feed_dict = {X: X_batch, y:y_batch})\n",
    "                summary_str_test = acc_summary_test.eval(feed_dict = {X: mnist.test.images, y:mnist.test.labels})\n",
    "                step = epoch*(mnist.train.num_examples // batch_size) + iteration\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "                file_writer.add_summary(summary_str_test, step)\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict = {X: X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict = {X: mnist.test.images, y:mnist.test.labels})\n",
    "        if(epoch % 10 ==0):\n",
    "            print(\"Epoch:\", epoch, \"Train Accuracy:\", acc_train, \"Test Accuracy:\", acc_test)\n",
    "    save_path = saver.save(sess, \"./final_mnist.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph ve performans grafikleri aşağıdadır:\n",
    "\n",
    "Graph: ![alt text](images/graph_mlp.png \"Graph\")\n",
    "Performans: ![alt text](images/tr_test_acc_mlp.png \"Performans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
