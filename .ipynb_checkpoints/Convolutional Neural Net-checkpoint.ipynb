{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets\n",
    "\n",
    "Bu notebook'ta öncelikle hard disk'teki imageları parçalar halinde okuyup, sonrasında bir CNN öğreneceğiz. CNNlerle ilgili en anlaşılır bilgiyi [şu](http://www.deeplearningbook.org/contents/convnets.html) linkte bulabilirsiniz (İngilizce kaynak).\n",
    "\n",
    "Bu CNN'in amacı, köpek fotoğraflarından köpeklerin hangi türe ait olduğunu öğrenmek. Bu verisetini kullanabilmek için Kaggle'daki [yarışmadan](https://www.kaggle.com/c/dog-breed-identification) indirmek gerekiyor. Ben train verisetini indirip \"dog_data/train\" diye bir klasörün içine attım. Sınıfların etiketleri ise \"dog_data/labels.csv\" içinde. Siz farklı bir klasör kullanırsanız aşağıdaki directory değişkenlerini ona göre belirlemeniz gerek.\n",
    "\n",
    "Şimdi kütüphaneleri ve fonksiyonları oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "\n",
    "def load_images(input_dir, batch_shape):\n",
    "    \"\"\"Girdi klasöründen görselleri parça parça oku,\n",
    "        Image'ı istenilen boyuta resize edip kare hale getirmek için siyah padding ekle.\n",
    "      Args:\n",
    "        input_dir: Görsellerin bulunduğu girdi klasörünün adresi\n",
    "        batch_shape: parça şekli, i.e. [batch_size, height, width, 3]\n",
    "      Yields:\n",
    "        filenames: Dosyaların adres ve uzantı olmadan isimleri\n",
    "        images: bu batch'teki görselleri içeren bir array\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    for filepath in tf.gfile.Glob(os.path.join(input_dir, '*.jpg')):\n",
    "        image = Image.open(filepath)\n",
    "        img_w, img_h = image.size\n",
    "        ims = [img_w, img_h]\n",
    "        max_p = np.argmax(ims)\n",
    "        max_v = ims[max_p]\n",
    "        min_v = ims[1-max_p]\n",
    "        new_size = (batch_shape[1], batch_shape[2])\n",
    "        bg = Image.new(\"RGB\", new_size)\n",
    "        rat = float(batch_shape[1])/max_v\n",
    "        new_max = rat*max_v\n",
    "        new_min = rat*min_v\n",
    "        ims[max_p] = int(new_max)\n",
    "        ims[1-max_p] = int(new_min)\n",
    "        image = image.resize(ims)\n",
    "        bg.paste(image, (int((new_size[0]-ims[0])/2),\n",
    "                      int((new_size[1]-ims[1])/2)))\n",
    "        image = np.array(bg).astype(np.float) / 255 # 0-255 arasındaki image'ı 0-1 arasına getir\n",
    "        images.append(image)\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            images = np.array(images)\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = []\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        images = np.array(images)\n",
    "        yield filenames, images\n",
    "\n",
    "def get_labels(all_labels, filenames):\n",
    "    classes = []\n",
    "    for fname in filenames:\n",
    "        fname = fname.replace(\".jpg\",\"\")\n",
    "        classes.append(all_labels[fname])\n",
    "    return(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öncelikle yapmak istediğimiz şey, görsellerimizi yükleyip, istediğimiz formata getirip bize verecek bir fonksiyon yazmak. Veri setimizdeki görseller maalesef aynı boyutta değil, hatta boyutları birbirinden gerçekten çok farklı. Bu yüzden bu görselleri CNN'e verebilmek için standartlaştırmamız gerekiyor. Standartlaştırmamız gerekmeyen CNN yapıları da mevcut ancak şimdilik oraya girmiyoruz. Ben gayet rastgele olarak görsellerin 128 x 128 olması gerektiğine karar verdim. Bu değeri siz aşağıdaki 'im_size' değerini değiştirerek belirleyebilirsiniz. \n",
    "\n",
    "Dikkat edilmesi gereken bir diğer nokta görsellerin kare olmadığı gerçeği. Bu yüzden, görseldeki objelerin proporsiyonunu bozmamak adına kısa olan kenara siyah şeritler eklemeye karar verdim. Bu önişleme yöntemi tamamen kişinin seçimine kalmış bir şey. Siz başka şeyler de deneyebilirsiniz.\n",
    "\n",
    "'load_images' fonksiyonu, veri setimizi yüklemek için oluşturduğumuz bir generator fonksiyonu. Bu fonksiyon sırasıyla şunları yapıyor:\n",
    "\n",
    "- Dosyaların olduğu klasörün adresini alıyor\n",
    "- Bu adresteki '.jpg' uzantılı dosyaları buluyor.\n",
    "- Bu dosyaları, sırasıyla, batch_size'a kadar olacak şekilde açıyor\n",
    "- Açtığı image'ı belli bir boyuta getirmek için şunları yapıyor:\n",
    "    - Image'ın hangi boyutunun büyük olduğunu buluyor\n",
    "    - im_size'ın büyük olan kenara oranını buluyor\n",
    "    - Bu orana göre büyük olan kenarı im_size'a, küçük olan kenarı ise yine bu orana bağlı olarak daha küçük bir değere çekiyor\n",
    "    - Küçük olan kenarı im_size'a tamamlamak için siyah bir şerit çekiyor.\n",
    "- Image istenilen boyuta geldikten sonra image'ı normalize edip array'e ekliyor\n",
    "- Array boyutu batch_size'a ulaşınca bu array'i ve array'deki dosyaların isimlerini döndürüyor\n",
    "- Bunu klasördeki tüm imagelar dönene kadar yapıyor\n",
    "\n",
    "Dikkat ederseniz bu fonksiyon klasördeki image sayısından bağımsız olarak çalışıyor. Bu python generatorlarının bir getirisi. 'yield' anahtar kelimesini araştırarak generatorlar nasıl çalışıyor öğrenebilirsiniz.\n",
    "\n",
    "İkinci oluşturduğumuz fonksiyon ise dosya ismiyle bize sınıfı döndürüyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki hücre'de önce görsellerin etiketlerini alıyoruz. Bu etiketler kategorik olarak verilmiş durumda. Ancak tensorflow'da kategorik değişkenlerle çalışamıyoruz. Bu kategorik sınıfları, numerik sınıflara çevirmek gerekiyor. Bunu da Scikit-learn kütüphanesinden 'LabelEncoder' fonksiyonu ile yapabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "      <th>num_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed  num_labels\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull          19\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo          37\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese          85\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick          15\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever          49"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = os.getcwd() + \"/dog_data/train/\"\n",
    "label_dir = os.getcwd() + \"/dog_data/labels.csv\"\n",
    "labels = pd.read_csv(label_dir)\n",
    "batch_size = 100 # Kafamıza göre belirledik, normalde 16, 32, 50 gibi değerler olur\n",
    "im_size = 28 # Kafamıza göre belirledik\n",
    "batch_shape = [batch_size, im_size, im_size, 3]\n",
    "\n",
    "# Kategorik değişkeni numerik yap\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels[\"breed\"])\n",
    "num_class = len(le.classes_)\n",
    "print(num_class)\n",
    "labels[\"num_labels\"] = le.transform(labels[\"breed\"])\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrame'i dictionary'ye çevir\n",
    "all_labels = labels.set_index('id')['num_labels'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi hep yaptığımız gibi tensorflow değişkenlerini ve graph'ı tanımlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ağırlıkları ve bias'ı başlatacak fonksiyonlar\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Layerları oluşturan fonksiyonlar\n",
    "def conv2d(x, W): # Convolution layer\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x): # Max pool layer\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "conv_size = 15\n",
    "\n",
    "# 5x5 convolution 32 feature\n",
    "W_conv1 = weight_variable([conv_size, conv_size, 3, 32])\n",
    "\n",
    "# 32 bias\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = (None, im_size, im_size, 3), name = \"x\")\n",
    "y_ = tf.placeholder(tf.int64, shape = (None), name = \"y_\")\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([conv_size, conv_size, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([int(im_size/4) * int(im_size/4) * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, int(im_size/4)*int(im_size/4)*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, num_class])\n",
    "b_fc2 = bias_variable([num_class])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "correct = tf.nn.in_top_k(y_conv, y_, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oluşturduğumuz CNN modelinde 2 convolutional layer, 2 de max pool layer'ı bulunuyor. CNN modelinin tüm yapısı şu şekildedir:\n",
    "\n",
    "![alt text](images/CNN.png \"CNN\")\n",
    "\n",
    "\n",
    "Bu modeli olduğu gibi [tensorflow dökümanından](https://www.tensorflow.org/tutorials/deep_cnn) aldım. Sadece resim ve filtre boyutları farklı. Siz isterseniz layerlarınızı değiştirerek yeni modeller deneyebilirsiniz. Ancak dikkat etmeniz gereken bazı noktalar var.\n",
    "\n",
    "1- Layerların output'u ve bir sonraki layerların inputunun boyutu uyuşmalı. Boyut uyuşmazlığı olduğu zaman hata verecektir. Ben bunu sağlayabilmek için önce resimleri belli bir boyuta getirdim. Eğer resimler kare değilse kısa kenarını uzun kenarına tamamlayacak şekilde siyah bant ekledim. Sonrasında ise her layer bir önceki layerla uyumlu olsun diye filtre boyutunu resim boyutuna bağladım.\n",
    "\n",
    "2- Filtre dizaynı ve boyutlarına dair detayları ilgili [kitaptan](http://www.deeplearningbook.org/) ulaşabilirsiniz.\n",
    "\n",
    "3- Eğer kendiniz denemek isterseniz diye baştan belirteyim, training GPU ile bile biraz uzun sürüyor. Bu ufak model bile oldukça zaman alıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training batch average accuracy 0.00834951\n",
      "step 10, training batch average accuracy 0.0408473\n",
      "step 20, training batch average accuracy 0.148129\n",
      "step 30, training batch average accuracy 0.357326\n",
      "step 40, training batch average accuracy 0.603689\n",
      "step 50, training batch average accuracy 0.784078\n",
      "step 60, training batch average accuracy 0.895922\n",
      "step 70, training batch average accuracy 0.964757\n",
      "step 80, training batch average accuracy 0.992621\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(90):\n",
    "        bname = 0\n",
    "        tr_accur = 0\n",
    "        for filenames, images in load_images(image_dir, batch_shape):\n",
    "            bname += 1\n",
    "            y_temp = get_labels(all_labels, filenames)\n",
    "            train_step.run(feed_dict={x: images, y_: y_temp, keep_prob: 0.8})\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: images, y_: y_temp, keep_prob: 1.0})\n",
    "            tr_accur += train_accuracy\n",
    "        tr_accur /= bname\n",
    "        if(i%10 == 0):\n",
    "            print('step %d, training batch average accuracy %g' % (i, tr_accur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu noktada dikkat etmeniz gereken bazı şeyler var. Normalde, bu tip bir öğrenme cross-validation ile yapılmalıdır. Çünkü yapay sinir ağları (veya herhangi diğer bir makine öğrenmesi modeli, yeterince büyükse) training verisini ezberlemeye meyillidir. Bunu takip edebilmek için, her epoch'ta daha önce görmediği bir validation verisiyle performansını test etmek gerekir. Cross-validation ise bunu birden fazla kez, farklı farklı setlerle yapan yöntem. Ancak burada amaç CNN eğitimini göstermek olduğu için ben bunu eklemedim. Kodu değiştirirken sizin bunu eklemenizi tavsiye ederim.\n",
    "\n",
    "Daha detaylı uygulamalı bilgiler için [Hands-On Machine Learning with Scikit-Learn and TensorFlow](http://shop.oreilly.com/product/0636920052289.do) kitabına bakabilirsiniz. Hem machine learning için en iyi yaklaşımları, hem de tensorflow kodlarını içeriyor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
